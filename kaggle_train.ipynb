{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7483333,"sourceType":"datasetVersion","datasetId":4340387}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-02-02T15:43:20.819901Z","iopub.execute_input":"2024-02-02T15:43:20.820387Z","iopub.status.idle":"2024-02-02T15:43:22.195130Z","shell.execute_reply.started":"2024-02-02T15:43:20.820337Z","shell.execute_reply":"2024-02-02T15:43:22.194070Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\nimport torch\nfrom torch import *\ndataset_x = torch.load(\"/kaggle/input/zip-40k-dataset-cxr/final_x/final_x.pt\")\ndataset_y = torch.load(\"/kaggle/input/zip-40k-dataset-cxr/final_y (1).pt\")","metadata":{"execution":{"iopub.status.busy":"2024-02-02T15:43:23.241116Z","iopub.execute_input":"2024-02-02T15:43:23.241655Z","iopub.status.idle":"2024-02-02T15:44:30.217280Z","shell.execute_reply.started":"2024-02-02T15:43:23.241625Z","shell.execute_reply":"2024-02-02T15:44:30.216389Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":" ","metadata":{"execution":{"iopub.status.busy":"2024-01-28T18:12:52.599672Z","iopub.execute_input":"2024-01-28T18:12:52.600490Z","iopub.status.idle":"2024-01-28T18:12:52.605967Z","shell.execute_reply.started":"2024-01-28T18:12:52.600456Z","shell.execute_reply":"2024-01-28T18:12:52.605126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nxtr, xts, ytr, yts = train_test_split(dataset_x, dataset_y, test_size=0.2, shuffle=True, stratify=dataset_y)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T15:47:09.790644Z","iopub.execute_input":"2024-02-02T15:47:09.791211Z","iopub.status.idle":"2024-02-02T15:47:13.130873Z","shell.execute_reply.started":"2024-02-02T15:47:09.791180Z","shell.execute_reply":"2024-02-02T15:47:13.129987Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"xtr.size()","metadata":{"execution":{"iopub.status.busy":"2024-02-02T15:47:16.122820Z","iopub.execute_input":"2024-02-02T15:47:16.123286Z","iopub.status.idle":"2024-02-02T15:47:16.132167Z","shell.execute_reply.started":"2024-02-02T15:47:16.123237Z","shell.execute_reply":"2024-02-02T15:47:16.131090Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"torch.Size([32301, 1, 224, 224])"},"metadata":{}}]},{"cell_type":"code","source":"xts.size()","metadata":{"execution":{"iopub.status.busy":"2024-01-28T18:30:04.457286Z","iopub.execute_input":"2024-01-28T18:30:04.458167Z","iopub.status.idle":"2024-01-28T18:30:04.463518Z","shell.execute_reply.started":"2024-01-28T18:30:04.458134Z","shell.execute_reply":"2024-01-28T18:30:04.462587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import *\nmy_dataset = torch.utils.data.TensorDataset(xtr,ytr) # create your datset\nmy_dataloader = torch.utils.data.DataLoader(my_dataset,batch_size=32,\n                                          shuffle=True, num_workers=2)\n\nmy_dataset = torch.utils.data.TensorDataset(xts,yts) # create your datset\nmy_tdataloader = torch.utils.data.DataLoader(my_dataset,batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T15:47:21.157016Z","iopub.execute_input":"2024-02-02T15:47:21.157855Z","iopub.status.idle":"2024-02-02T15:47:21.165488Z","shell.execute_reply.started":"2024-02-02T15:47:21.157816Z","shell.execute_reply":"2024-02-02T15:47:21.164201Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"len(my_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T15:47:24.965675Z","iopub.execute_input":"2024-02-02T15:47:24.966036Z","iopub.status.idle":"2024-02-02T15:47:24.972367Z","shell.execute_reply.started":"2024-02-02T15:47:24.966008Z","shell.execute_reply":"2024-02-02T15:47:24.971324Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"1010"},"metadata":{}}]},{"cell_type":"code","source":"from IPython.display import clear_output","metadata":{"execution":{"iopub.status.busy":"2024-02-02T15:47:28.389422Z","iopub.execute_input":"2024-02-02T15:47:28.389788Z","iopub.status.idle":"2024-02-02T15:47:28.394584Z","shell.execute_reply.started":"2024-02-02T15:47:28.389752Z","shell.execute_reply":"2024-02-02T15:47:28.393536Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"rep = []","metadata":{"execution":{"iopub.status.busy":"2024-02-02T15:47:31.530119Z","iopub.execute_input":"2024-02-02T15:47:31.530998Z","iopub.status.idle":"2024-02-02T15:47:31.534994Z","shell.execute_reply.started":"2024-02-02T15:47:31.530963Z","shell.execute_reply":"2024-02-02T15:47:31.533905Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"feature_vec=[]","metadata":{"execution":{"iopub.status.busy":"2024-02-02T15:47:33.605691Z","iopub.execute_input":"2024-02-02T15:47:33.606087Z","iopub.status.idle":"2024-02-02T15:47:33.610326Z","shell.execute_reply.started":"2024-02-02T15:47:33.606050Z","shell.execute_reply":"2024-02-02T15:47:33.609226Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nfrom tempfile import TemporaryDirectory\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader, random_split\n\nimport torch\nimport torchvision.models as models\n\n\nif torch.cuda.is_available():\n    print('CUDA is available. Working on GPU')\n    device = torch.device('cuda')\nelse:\n    print('CUDA is not available. Working on CPU')\n    device = torch.device('cpu')\n\n\n\nimport timm","metadata":{"execution":{"iopub.status.busy":"2024-02-02T15:47:49.207632Z","iopub.execute_input":"2024-02-02T15:47:49.208002Z","iopub.status.idle":"2024-02-02T15:47:54.891016Z","shell.execute_reply.started":"2024-02-02T15:47:49.207972Z","shell.execute_reply":"2024-02-02T15:47:54.890135Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"CUDA is available. Working on GPU\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Densenet201","metadata":{}},{"cell_type":"code","source":"# from timm\npretrained_model_name = 'densenet201'\nmodel_d201 = timm.create_model(pretrained_model_name, pretrained=True)\n\nnum_channels = 1  # for grayscale images, but it could be any number\n# Extract the first conv layer's parameters\nnum_filters = model_d201.features.conv0.out_channels\nkernel_size = model_d201.features.conv0.kernel_size\nstride = model_d201.features.conv0.stride\npadding = model_d201.features.conv0.padding\nconv1 = torch.nn.Conv2d(num_channels, num_filters, kernel_size=kernel_size, stride=stride, padding=padding)\noriginal_weights = model_d201.features.conv0.weight.data.mean(dim=1, keepdim=True)\nconv1.weight.data = original_weights.repeat(1, num_channels, 1, 1)\nmodel_d201.features.conv0 = conv1\n\n# Freeze only the convolutional layers of the pre-trained model\nfor param in model_d201.parameters():\n    if isinstance(param, nn.Conv2d):\n        param.requires_grad = False\n\n\n\n# Modify the model head for fine-tuning\nnum_features = 2048\n\n# Additional linear layer and dropout layer\nmodel_d201.fc = nn.Sequential(\n    nn.Linear(num_features, 256),  # Additional linear layer with 256 output features\n    nn.ReLU(inplace=True),         # Activation function (you can choose other activation functions too)\n    nn.Dropout(0.5),               # Dropout layer with 50% probability\n    nn.Linear(256, 4)\n)\n\n#model_d201 = torch.nn.DataParallel(model_d201, device_ids = [0,1]).to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-02T15:48:08.043094Z","iopub.execute_input":"2024-02-02T15:48:08.044003Z","iopub.status.idle":"2024-02-02T15:48:10.378293Z","shell.execute_reply.started":"2024-02-02T15:48:08.043969Z","shell.execute_reply":"2024-02-02T15:48:10.377413Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/81.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f31f9b446eea4d42a2b2c0e27132a3dd"}},"metadata":{}}]},{"cell_type":"markdown","source":"# model InceptionV3","metadata":{}},{"cell_type":"code","source":"\n\n# from timm\npretrained_model_name = \"inception_v3\"\nmodel_inv3 = timm.create_model(pretrained_model_name, pretrained=True)\n#print(model)\nnum_channels = 1  # for grayscale images, but it could be any number\n# Extract the first conv layer's parameters\nnum_filters = model_inv3.Conv2d_1a_3x3.conv.out_channels\nkernel_size = model_inv3.Conv2d_1a_3x3.conv.kernel_size\nstride = model_inv3.Conv2d_1a_3x3.conv.stride\npadding = model_inv3.Conv2d_1a_3x3.conv.padding\nconv1 = torch.nn.Conv2d(num_channels, num_filters, kernel_size=kernel_size, stride=stride, padding=padding)\noriginal_weights = model_inv3.Conv2d_1a_3x3.conv.weight.data.mean(dim=1, keepdim=True)\nconv1.weight.data = original_weights.repeat(1, num_channels, 1, 1)\nmodel_inv3.Conv2d_1a_3x3.conv = conv1\n\n# Freeze only the convolutional layers of the pre-trained model\nfor param in model_inv3.parameters():\n    if isinstance(param, nn.Conv2d):\n        param.requires_grad = False\n\n\n\n# Modify the model head for fine-tuning\nnum_features = 2048\n\n# Additional linear layer and dropout layer\nmodel_inv3.fc = nn.Sequential(\n    nn.Linear(num_features, 256),  # Additional linear layer with 256 output features\n    nn.ReLU(inplace=True),         # Activation function (you can choose other activation functions too)\n    nn.Dropout(0.5),               # Dropout layer with 50% probability\n    nn.Linear(256, 4)\n)\n\n#model_inv3 = torch.nn.DataParallel(model_inv3, device_ids = [0,1]).to(device)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-02T15:48:16.928023Z","iopub.execute_input":"2024-02-02T15:48:16.928398Z","iopub.status.idle":"2024-02-02T15:48:18.352031Z","shell.execute_reply.started":"2024-02-02T15:48:16.928360Z","shell.execute_reply":"2024-02-02T15:48:18.350916Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/95.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2504844af9248e7b0f3b88169973669"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Model ResNet50","metadata":{}},{"cell_type":"code","source":"\n# from timm\nmodel_R50 = \"resnet50\"\nmodel_R50 = timm.create_model(model_R50, pretrained=True)\n\nnum_channels = 1  # for grayscale images, but it could be any number\n# Extract the first conv layer's parameters\nnum_filters = model_R50.conv1.out_channels\nkernel_size = model_R50.conv1.kernel_size\nstride = model_R50.conv1.stride\npadding = model_R50.conv1.padding\nconv1 = torch.nn.Conv2d(num_channels, num_filters, kernel_size=kernel_size, stride=stride, padding=padding)\noriginal_weights = model_R50.conv1.weight.data.mean(dim=1, keepdim=True)\nconv1.weight.data = original_weights.repeat(1, num_channels, 1, 1)\nmodel_R50.conv1 = conv1\n\n\n# Freeze only the convolutional layers of the pre-trained model\nfor param in model.parameters():\n    if isinstance(param, nn.Conv2d):\n        param.requires_grad = False\n\n\n\n# Modify the model head for fine-tuning\nnum_features = 2048\n\n# Additional linear layer and dropout layer\nmodel.fc = nn.Sequential(\n    nn.Linear(num_features, 256),  # Additional linear layer with 256 output features\n    nn.ReLU(inplace=True),         # Activation function (you can choose other activation functions too)\n    nn.Dropout(0.5),               # Dropout layer with 50% probability\n    nn.Linear(256, 4)    # Final prediction fc layer\n)\n\n#model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-02T15:57:08.598666Z","iopub.execute_input":"2024-02-02T15:57:08.599561Z","iopub.status.idle":"2024-02-02T15:57:09.236900Z","shell.execute_reply.started":"2024-02-02T15:57:08.599521Z","shell.execute_reply":"2024-02-02T15:57:09.235863Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class EnsembleModel(nn.Module):   \n    def __init__(self, modelA, modelB):\n        super().__init__()\n        self.modelA = modelA\n        self.modelB = modelB\n        self.classifier = nn.Linear(2000, 4)\n        \n    def forward(self, x):\n        x1 = self.modelA(x)\n        x2 = self.modelB(x)\n        \n        x = torch.cat((x1,x2), dim=1)\n        x.size()\n        out = self.classifier(x)\n        return out\n    \nensemble_model = EnsembleModel(model_d201,model_R50)\n\nfor param in ensemble_model.parameters():\n    param.requires_grad = False\n\nfor param in ensemble_model.classifier.parameters():\n    param.requires_grad = True    \n\nensemble_model = torch.nn.DataParallel(ensemble_model, device_ids = [0,1]).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T17:31:42.805508Z","iopub.execute_input":"2024-02-02T17:31:42.805967Z","iopub.status.idle":"2024-02-02T17:31:42.844935Z","shell.execute_reply.started":"2024-02-02T17:31:42.805924Z","shell.execute_reply":"2024-02-02T17:31:42.843923Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer_ft = optim.SGD(ensemble_model.parameters(), lr=0.001, momentum=0.9)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T17:31:46.290073Z","iopub.execute_input":"2024-02-02T17:31:46.290793Z","iopub.status.idle":"2024-02-02T17:31:46.301967Z","shell.execute_reply.started":"2024-02-02T17:31:46.290757Z","shell.execute_reply":"2024-02-02T17:31:46.301056Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"rep = []","metadata":{"execution":{"iopub.status.busy":"2024-02-02T17:31:49.292036Z","iopub.execute_input":"2024-02-02T17:31:49.292450Z","iopub.status.idle":"2024-02-02T17:31:49.297278Z","shell.execute_reply.started":"2024-02-02T17:31:49.292416Z","shell.execute_reply":"2024-02-02T17:31:49.296068Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nbatch_size=32\nnum_epochs=30\nval_size = len(my_tdataloader)\ntrain_size = len(my_dataloader) \n\nlosses = [] \naccuracies = [] \nval_losses = [] \nval_accuracies = [] \n# Train the model \ncnt = 0\nx = range(0,num_epochs)\nfor epoch in x: \n    cnt = 0\n    for i, (images, labels) in enumerate(my_dataloader): \n        # Forward pass \n        images=images.to(device) \n        labels=labels.type(torch.LongTensor).to(device) \n        outputs = ensemble_model(images) \n        loss = criterion(outputs, labels) \n        \n        # Backward pass and optimization \n        optimizer_ft.zero_grad() \n        loss.backward() \n        optimizer_ft.step() \n        cnt = cnt+1\n        print(cnt,end=' ')\n        if cnt == 1010 :\n            clear_output()\n            cnt = 0\n        _, predicted = torch.max(outputs.data, 1)\n        \n    acc = (predicted == labels).sum().item() / labels.size(0) \n    accuracies.append(acc) \n    losses.append(loss.item()) \n\n    # Evaluate the model on the validation set\t\n    rep.append('Epoch [{}/{}],Loss:{:.4f},Accuracy:{:.2f}'.format( \n        epoch+1, num_epochs, loss.item(),acc))\n    print('Epoch [{}/{}],Loss:{:.4f},Accuracy:{:.2f}'.format( \n        epoch+1, num_epochs, loss.item(),acc))","metadata":{"execution":{"iopub.status.busy":"2024-02-02T17:32:19.984099Z","iopub.execute_input":"2024-02-02T17:32:19.984528Z","iopub.status.idle":"2024-02-02T17:32:28.731809Z","shell.execute_reply.started":"2024-02-02T17:32:19.984493Z","shell.execute_reply":"2024-02-02T17:32:28.730213Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1744269944.py:12: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n  x = range(0,num_epochs)\n","output_type":"stream"},{"name":"stdout","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[53], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m images\u001b[38;5;241m=\u001b[39mimages\u001b[38;5;241m.\u001b[39mto(device) \n\u001b[1;32m     18\u001b[0m labels\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mLongTensor)\u001b[38;5;241m.\u001b[39mto(device) \n\u001b[0;32m---> 19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mensemble_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels) \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization \u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:200\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:102\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    100\u001b[0m         thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m thread \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[0;32m--> 102\u001b[0m         \u001b[43mthread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     _worker(\u001b[38;5;241m0\u001b[39m, modules[\u001b[38;5;241m0\u001b[39m], inputs[\u001b[38;5;241m0\u001b[39m], kwargs_tup[\u001b[38;5;241m0\u001b[39m], devices[\u001b[38;5;241m0\u001b[39m], streams[\u001b[38;5;241m0\u001b[39m])\n","File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:27:51.634632Z","iopub.execute_input":"2024-01-28T13:27:51.635348Z","iopub.status.idle":"2024-01-28T13:27:51.639318Z","shell.execute_reply.started":"2024-01-28T13:27:51.635315Z","shell.execute_reply":"2024-01-28T13:27:51.638360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sn\nimport pandas as pd\n\ny_pred = []\ny_true = []  \n\n# iterate over test data\nfor inputs, labels in my_tdataloader:\n        output = ensemble_model(inputs) # Feed Network\n\n        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n        y_pred.extend(output) # Save Prediction\n        \n        labels = labels.data.cpu().numpy()\n        y_true.extend(labels) # Save Truth\n\n# constant for classes\nclasses = ('COVID','Normal','Pneumonia','Bacterial infection')\n\n# Build confusion matrix\ncf_matrix = confusion_matrix(y_true, y_pred)\ndf_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n                     columns = [i for i in classes])\nplt.figure(figsize = (12,7))\nsn.heatmap(df_cm, annot=True)\nplt.savefig('output.png')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_true, y_pred))\nclassification_report(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T07:29:35.678264Z","iopub.status.idle":"2024-01-27T07:29:35.678592Z","shell.execute_reply.started":"2024-01-27T07:29:35.678432Z","shell.execute_reply":"2024-01-27T07:29:35.678447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}